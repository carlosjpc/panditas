# <img height="45" src="https://raw.githubusercontent.com/ivansabik/panditas/master/doc/icon.png" /> panditas

Data Pipelines builder and scheduler using Pandas and S3

### Models

<img src="https://raw.githubusercontent.com/ivansabik/panditas/master/doc/sample_data_pipeline.png" />

#### Setting

- S3 Host
- AWS Secret Key
- AWS Access Key

#### Input DataFrame

- Date Columns
- Data Types by Column
- Format (CSV, Excel, SQL)
- Local path
- Preview Rows
- Row count
- S3 URL
- Sheet Index
- Sheet Name (In case of an Excel file, sheets are handled as single DF)
- Table Name
- Database provider (mysql)
- Database host
- Database user
- Database pass
- Database port

#### Data Transformation

- Calculated Column
- Columns Subset
- Conditional Fill
- Constant Column
- Filter
- Format Columns (Currency, Date, etc)
- Merge
- Pivot Table (for grouping by)
- Remove Duplicates
- Rename Column
- Replace Text
- Sort by Columns
- Value Mapper

#### Output DataFrame



#### Data Pipeline Graph

- Parameters (Start Date, End Date, Year, Agency Number, Claim Number, Policy Number, etc)


### Credits

"gummy bear" icon by emilegraphics from the Noun Project.
